{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Smaller DFs by Selecting Relevant Columns\n",
    "\n",
    "### Classifications\n",
    "\n",
    "| Field  | Meaning  | Values\n",
    "|---|---|---|\n",
    "| ClassificationID  | Used to link entries in `ClassificationXRefs`  | int, unique |\n",
    "| Classification  | Actual class values | (string, 8 levels, most common 'Documentatie')  |\n",
    "| AATCN |  Classification into types of objects | (string, 38 levels, uniform, e.g. 'Boeken') |\n",
    "| SubClassification | Extra classifications | (string, 16 levels, most common 'Audiovisueel') |\n",
    "| SubClassification2 | More extra classifications | (string, 14 levels, uniform, e.g. 'Drukwerk') |\n",
    "\n",
    "<br>\n",
    "\n",
    " - `SubClassification3` is empty\n",
    " - idea: create tuple of `(Classification, SubClassification, SubClassification2)` as the single classification feature\n",
    " \n",
    "\n",
    "### ClassificationXRefs\n",
    "\n",
    "| Field  | Meaning  | Values\n",
    "|---|---|---|\n",
    "| ClassificationXRefID  | Only used in this table?  | int, unique |\n",
    "| ClassificationID  | Used to link entries in `Classifications` | correspond to values of <br> `Classifications.Classification`, non-uniform counts  |\n",
    "| ID |  Used to link entries in `Objects` | correspond to values of `Objects.ID`, uniform |\n",
    "| TableID | ID of this table (for other contexts) | single value: 108 |\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "### Departments\n",
    "\n",
    "| Field  | Meaning  | Values\n",
    "|---|---|---|\n",
    "| DepartmentID  | Used to link entries in Objects  | int, unique |\n",
    "| Department  | Actual department names | (int, 18 levels, most not assigned, others uniform)  |\n",
    "| Mnemonic |  Shorthand for the departmant name (field Department) | (same as Department) |\n",
    "\n",
    "<br>\n",
    "\n",
    " - is `MainTableID` the ID of the departments in the main table? -> would be useful in that case for unification\n",
    "\n",
    "\n",
    "### Objects\n",
    "\n",
    "\n",
    "| Field  | Meaning  | Values\n",
    "|---|---|---|\n",
    "| ObjectID  | Linked to entries in `ClassificationXRefs`  | int, unique |\n",
    "| DepartmentID  | Linked to entries in `Departments` | corresponds to `Departments.DepartmentID`  |\n",
    "| ClassificationID |  Linked to entries in `Classifications` <br>and `ClassificationXRefs` | corresponds to `ClassificationID` in both tables |\n",
    "| ObjectName | Name of the type of object | (string, 163 levels, most common 'Foto') |\n",
    "| Title | The object's title | string |\n",
    "| Description | The object's description | string |\n",
    "| Provenance | Description of the object's history | string |\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    " - `ObjectNumber` seems to be an external ID for objects (is unique, has prefixes such as \"TM\", \"RV\", \"NL\")\n",
    " - `SortNumber` is similar to `ObjectNumber`\n",
    " - what does `ObjectCount` indicate? does `ObjectCount > 1` imply that entries should be merged?\n",
    " - what do `DateBegin` and `DateEnd` refer to? (most objects have `DateEnd == DateBegin`, latest date is 1990)\n",
    " - same for `Dated` -> which date is this?\n",
    " - technical properties:\n",
    "     - Medium is the object's material\n",
    "     - Dimensions\n",
    "     - Signed, Inscribed, Markings\n",
    "     - CreditLine: by whome the object was given\n",
    " - Exhibitions: Title of the exhibition the object was displayed at\n",
    " - Provenance: Description of how the object was acquired by the museum\n",
    " - **incomplete, TODO: go through the remaining columns**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Other Notes\n",
    "\n",
    " - `EnteredDate` is in all tables, earliest values around 1995, not uniformly distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 'tcp:azuredfserv.database.windows.net' \n",
    "database = 'Azuredf' \n",
    "username = 'Demouser' \n",
    "password = 'Knxdde#77' \n",
    "driver='{ODBC Driver 17 for SQL Server}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_to_DataFrame(connection, table_name, keys=None, until=None, random_n=None):\n",
    "    \n",
    "    keys = \"*\" if not keys else \",\".join(keys)\n",
    "    if not until:\n",
    "        until = \"\"\n",
    "    until = f\"TOP {until}\" if until else \"\"\n",
    "    sample = f\"TABLESAMPLE ({random_n} ROWS)\" if random_n else \"\"\n",
    "    query = f\"SELECT {until} {keys} FROM {table_name} {sample};\"\n",
    "    print(query)\n",
    "    df = pd.read_sql(query, connection)\n",
    "    return df\n",
    "\n",
    "\n",
    "def connect_to_DB():\n",
    "    return pyodbc.connect('DRIVER='+driver+';SERVER='+server+';PORT=1433;DATABASE='+database+';UID='+username+';PWD='+ password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get table names\n",
    "\n",
    "not necessary - tables defined manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "('HYT00', '[HYT00] [Microsoft][ODBC Driver 17 for SQL Server]Login timeout expired (0) (SQLDriverConnect)')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9a702b1f6d38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mconnect_to_DB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mq\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m\"SELECT t.name, t.modify_date FROM sys.tables t\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"Person\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-bc1a05029a1d>\u001b[0m in \u001b[0;36mconnect_to_DB\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconnect_to_DB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpyodbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DRIVER='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m';SERVER='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m';PORT=1433;DATABASE='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m';UID='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0musername\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m';PWD='\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m: ('HYT00', '[HYT00] [Microsoft][ODBC Driver 17 for SQL Server]Login timeout expired (0) (SQLDriverConnect)')"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t0 = time()\n",
    "with connect_to_DB() as conn:\n",
    "    print()\n",
    "    q  = \"SELECT t.name, t.modify_date FROM sys.tables t\"\n",
    "    tables = pd.read_sql(q, conn)\n",
    "    tables = tables[tables.name != \"Person\"]\n",
    "    print(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define table column keys & dump via connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = {\"Classifications\": (\"ClassificationID\", \"Classification\", \"AATCN\", \"SubClassification\", \"SubClassification2\"),\n",
    "       \"ClassificationXRefs\": (\"ClassificationXRefID\", \"ClassificationID\", \"ID\", \"TableID\"),\n",
    "       \"Departments\": (\"DepartmentID\", \"Department\", \"Mnemonic\"),\n",
    "       \"Objects\": (\"ObjectID\", \"DepartmentID\", \"ClassificationID\", \"ObjectName\", \"Title\", \"Description\", \"Provenance\")}\n",
    "\n",
    "tables = {}\n",
    "with connect_to_DB() as conn:\n",
    "    for table_name, key_ls in keys.items():\n",
    "        print(table_name)\n",
    "        tables[table_name] = table_to_DataFrame(conn, table_name, keys=key_ls, random_n=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: clean up, process, etc tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, tbl in tables.items():\n",
    "    tbl.to_csv(f\"tables/{key}.csv.gz\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
