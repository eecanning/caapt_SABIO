{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b41ef983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from ngrams import Ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3761e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TypicalityEngine:\n",
    "    def __init__(self, texts, **model_params):\n",
    "        default_params = dict(ns=3, documents=texts, precompute_freqs=True)\n",
    "        default_params.update(model_params)\n",
    "        self.model = Ngram(**default_params)\n",
    "        \n",
    "        # compute H\n",
    "        self.H = self.cond_entropy()\n",
    "        \n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def is_boundary_gram(gram):\n",
    "        return (gram.find(\"<s>\") >= 0) or (gram.find(\"</s>\") >= 0)\n",
    "\n",
    "#     def process_object(row):\n",
    "#         obj_prob = 0.\n",
    "\n",
    "#         l = 0\n",
    "#         for text in row:\n",
    "#             grams = list(self.model.iter_ngrams(text, as_tuples=True))\n",
    "#             for *rest, w in grams:\n",
    "#                 w_prob = self.model.cond_prob(w, *rest, log=True)\n",
    "#                 obj_prob += w_prob\n",
    "#                 l += 1\n",
    "\n",
    "#                 if not self.is_boundary_gram(\" \".join((*rest, w))):\n",
    "#                     yield (*rest, w), w_prob\n",
    "#         yield obj_prob/l\n",
    "        \n",
    "        \n",
    "    def process_object(self, row):\n",
    "        obj_prob = 0.\n",
    "        l = 0\n",
    "        for text in row:\n",
    "            grams = list(self.model.iter_ngrams(text, as_tuples=True))\n",
    "            for *rest, w in grams:\n",
    "                w_prob = self.model.cond_prob(w, *rest, log=True)\n",
    "                obj_prob += w_prob\n",
    "                l += 1\n",
    "\n",
    "                if not self.is_boundary_gram(\" \".join((*rest, w))):\n",
    "                    yield (*rest, w), abs(self.H - (-w_prob))\n",
    "                    \n",
    "        obj_typ = abs(self.H - (-obj_prob/l))\n",
    "        yield obj_typ\n",
    "        \n",
    "    @staticmethod\n",
    "    def entropy(probs):\n",
    "        arr = np.asarray(probs)\n",
    "        return -np.sum(arr*np.log2(arr))\n",
    "    \n",
    "    def cond_entropy(self):\n",
    "        H_context = self.entropy([self.model.prob(*gram.split(\" \")) \n",
    "                                  for gram in tqdm(self.model.vocab(2))])\n",
    "        H_joint = self.entropy([self.model.prob(*gram.split(\" \")) \n",
    "                                for gram in tqdm(self.model.vocab(3))])\n",
    "        return H_joint - H_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e963d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. \n",
    "df = pd.read_csv(\"../NMvW_data/v0.csv.gz\", \n",
    "                 dtype=dict(Provenance=\"string\", RelatedWorks=\"string\"))\n",
    "\n",
    "# TODO: save & load DF s.t. these lines are not necessary here                \n",
    "df[\"ObjectID\"] = df.ObjectID.astype(\"int\")\n",
    "df = df.set_index(\"ObjectID\")\n",
    "df = df.replace(np.nan, \"\")\n",
    "\n",
    "# 2.\n",
    "# def get_text(row):\n",
    "#     return row[[\"Title\", \"Description\"]]    \n",
    "    \n",
    "# texts = (t for i, row in df.iterrows() for t in get_text(row))\n",
    "\n",
    "texts = list(df[\"Title\"]) + list(df[\"Description\"])\n",
    "\n",
    "# ng = Ngram(ns=3, documents=texts, precompute_freqs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17320d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(2, 3)-grams: Padding documents...: 100%|██████████| 1159854/1159854 [00:01<00:00, 805944.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)-grams: Term Document Matrix constructed...\n",
      "(2, 3)-grams: Term frequencies precomputed...\n",
      "(2, 3)-grams: Init done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2781546/2781546 [00:12<00:00, 222735.72it/s]\n",
      "100%|██████████| 6203628/6203628 [00:28<00:00, 217717.42it/s]\n"
     ]
    }
   ],
   "source": [
    "typ_E = TypicalityEngine(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedb0803",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_typs = []\n",
    "obj_typs = []\n",
    "\n",
    "m = 10000\n",
    "for i, row in tqdm(df[[\"Title\", \"Description\"]][:m].iterrows(), total=m):\n",
    "    *w, o = list(typ_E.process_object(row))\n",
    "    obj_typs.append(o)\n",
    "    w_typs.extend(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6b905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_=plt.hist(obj_typs, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21494a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_= plt.hist(dict(w_typs).values(), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e777af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(map(lambda r: r[1][\"Title\"], df[[\"Title\", \"Description\"]][:m].iterrows()),\n",
    "          obj_typs), key=lambda tup: tup[1], reverse=False)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dd7fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = [len(row[\"Title\"]+row[\"Description\"]) \n",
    "        for i, row in df[[\"Title\", \"Description\"]][:m].iterrows()]\n",
    "\n",
    "# _=plt.hist(lens, bins=50)\n",
    "\n",
    "plt.plot(lens, obj_typs, \".\")\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "pearsonr(lens, obj_typs), spearmanr(lens, obj_typs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f237673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(dict(w_typs).items(), key=lambda tup: tup[1], reverse=False)[:100]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
